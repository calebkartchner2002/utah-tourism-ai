# Utah Tourism AI - Docker Compose Configuration
# Uses Docker Model Runner for local LLM hosting and MCP Gateway for tool integration

services:
  # Main tourism recommendation application
  utah-tourism-app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      # MCP Gateway endpoint for tool access
      - MCP_GATEWAY_ENDPOINT=http://mcp-gateway:8811/sse
      # Database connection
      - DATABASE_URL=postgresql+psycopg://utah_user:utah_password@postgres:5432/utah_tourism
    depends_on:
      - mcp-gateway
      - postgres
    # Bind to the LLM model
    models:
      llm:
        endpoint_var: LLM_API_URL
        model_var: LLM_MODEL_NAME

  # MCP Gateway - manages MCP servers for external tool access
  mcp-gateway:
    image: docker/mcp-gateway:latest
    use_api_socket: true
    volumes:
      - ./.env:/.env:ro
    command:
      - --transport=sse
      - --secrets=/.env
      # MCP servers for Utah tourism functionality
      - --servers=duckduckgo,fetch,openweather

  # PostgreSQL database for storing recommendations
  postgres:
    image: postgres:16-alpine
    environment:
      - POSTGRES_USER=utah_user
      - POSTGRES_PASSWORD=utah_password
      - POSTGRES_DB=utah_tourism
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

volumes:
  postgres_data:

# Docker Model Runner configuration
# Using Llama 3.2 for balanced performance and quality
models:
  llm:
    model: ai/llama3.2
    context_size: 8192
    runtime_flags:
      - "--temp"
      - "0.7"
      - "--top-p"
      - "0.9"
