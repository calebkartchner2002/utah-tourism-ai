# Utah Tourism AI - Docker Compose Configuration
# Uses Docker Model Runner for local LLM hosting and MCP Gateway for tool integration

services:
  # Main tourism recommendation application
  utah-tourism-app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      # MCP Gateway endpoint for tool access
      - MCP_GATEWAY_ENDPOINT=http://mcp-gateway:8811/sse
    depends_on:
      - mcp-gateway
    # Bind to the LLM model
    models:
      llm:
        endpoint_var: LLM_API_URL
        model_var: LLM_MODEL_NAME

  # MCP Gateway - manages MCP servers for external tool access
  mcp-gateway:
    image: docker/mcp-gateway:latest
    use_api_socket: true
    volumes:
      - ./.env:/.env:ro
    command:
      - --transport=sse
      - --secrets=/.env
      # MCP servers for Utah tourism functionality
      - --servers=duckduckgo,fetch,openweather

# Docker Model Runner configuration
# Using Llama 3.2 for balanced performance and quality
models:
  llm:
    model: ai/llama3.2
    context_size: 8192
    runtime_flags:
      - "--temp"
      - "0.7"
      - "--top-p"
      - "0.9"
